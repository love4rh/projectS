{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on Windows\n",
      "enc_param Z1o1ZU5vZVI3UVZMSVRqYU1laUpjdz09\n",
      "codeFile C:\\Workspace\\krx\\resource\\companyCodes.txt\n",
      "outputFolder C:\\Workspace\\krx\\output\\2022-05-28\\\n"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "from commonTool import *\n",
    "\n",
    "\n",
    "# Parameter 설정\n",
    "set_enc_param(encParamKey)\n",
    "\n",
    "print('enc_param', enc_param_value)\n",
    "print('codeFile', codePathFile)\n",
    "\n",
    "outputDirPath = outputRawPath + today() + os.path.sep\n",
    "\n",
    "print('outputFolder', outputDirPath, flush=True)\n",
    "\n",
    "\n",
    "# 데이터명 분석을 위한 데이터 페치\n",
    "def doFetchDataNames(referenceCodes, outPath, fetchType, funcGet):\n",
    "    print(fetchType, 'doing...', flush=True)\n",
    "    deli = '\\t'\n",
    "    # keyNames = ['ACCODE', 'ACC_NM', 'UNT_TYP', 'P_ACCODE', 'DATA1', 'DATA2', 'DATA3', 'DATA4', 'DATA5']\n",
    "    valueColumns = ['DATA1', 'DATA2', 'DATA3', 'DATA4', 'DATA5']\n",
    "\n",
    "    out = open(outPath + fetchType + '-accNames.txt', 'w', encoding='utf-8')\n",
    "    out.write('PCODE' + deli + 'ACCODE' + deli + 'NAME' + deli + 'P_ACCODE\\n')\n",
    "\n",
    "    for code in referenceCodes:\n",
    "        print('fetching', code, flush=True)\n",
    "        resp = funcGet(code)\n",
    "\n",
    "        if resp.status_code == 200:\n",
    "            # print(resp.text, flush=True)\n",
    "            obj = json.loads(resp.text)\n",
    "            if obj is None: continue\n",
    "            \n",
    "            data = obj['DATA']\n",
    "            if data is None:\n",
    "                continue\n",
    "\n",
    "            accodeMap = {}\n",
    "            \n",
    "            for rec in data:\n",
    "                if not rec['ACCODE'] in accodeMap:\n",
    "                    accNm = rec['ACC_NM'].lstrip('.').lstrip('*')\n",
    "                    accodeMap[rec['ACCODE']] = { 'name': accNm, 'pCode': rec['P_ACCODE'] }\n",
    "                    \n",
    "            # 추출한 데이터 명칭 저장\n",
    "            \n",
    "            for key in accodeMap.keys():\n",
    "                elem = accodeMap[key]\n",
    "                accNm = elem['name']\n",
    "                \n",
    "                out.write(code)\n",
    "                out.write(deli)\n",
    "                out.write(key)\n",
    "                out.write(deli)\n",
    "                out.write(accNm if elem['pCode'] is None else accodeMap[elem['pCode']]['name'] + '/' + accNm)\n",
    "                out.write(deli)\n",
    "                out.write('' if elem['pCode'] is None else elem['pCode'])\n",
    "                out.write('\\n')\n",
    "            \n",
    "        else:\n",
    "            print('fetch error ', code, resp.status_code)\n",
    "\n",
    "    out.close()\n",
    "    print(fetchType, 'done...', flush=True)\n",
    "\n",
    "    \n",
    "# codeList: 데이터를 가져올 회사 코드 목록\n",
    "# outFile: 결과를 저장할 파일\n",
    "# accCheck: 크롤링할 데이터 항목 맵. 항목 코드 --> 컬럼 위치\n",
    "# accCount: 데이터 항목 개수\n",
    "# funcGet: 크롤링 함수\n",
    "def crawlCompFinancials(codeList, outFile, accCheck, accCount, funcGet):\n",
    "    deli = '\\t'\n",
    "    valueColumns = ['DATA1', 'DATA2', 'DATA3', 'DATA4', 'DATA5']\n",
    "    \n",
    "    dataSet = [] # 크롤링 데이터 저장\n",
    "    for code in codeList:\n",
    "        print('fetching', code, flush=True)\n",
    "        resp = funcGet(code)\n",
    "\n",
    "        if resp.status_code == 200:\n",
    "            # print(resp.text, flush=True)\n",
    "            obj = json.loads(resp.text)\n",
    "            if obj is None: continue\n",
    "            \n",
    "            # DATA1 ~ DATA5의 기준 년월\n",
    "            yearName = [T[0:T.find('<')] for T in obj['YYMM']][0:len(valueColumns)]\n",
    "\n",
    "            data = obj['DATA']\n",
    "            if data is None:\n",
    "                continue\n",
    "\n",
    "            items = [extendList([code, title], accCount + 2) for title in yearName] # DATA1, ..., DATA4\n",
    "            \n",
    "            for rec in data:\n",
    "                if not rec['ACCODE'] in accCheck: # 데이터가 제대로 없는 경우임\n",
    "                    continue\n",
    "                    \n",
    "                # 저장할 위치\n",
    "                valCol = accCheck[rec['ACCODE']] + 2\n",
    "                \n",
    "                for c in range(0, len(items)):\n",
    "                    items[c][valCol] = rec[valueColumns[c]]\n",
    "\n",
    "            # 결과 저장용 배열에 추가\n",
    "            dataSet.extend(items)\n",
    "        else:\n",
    "            print('fetch error ', code, resp.status_code)\n",
    "\n",
    "    # 추출한 데이터 저장\n",
    "    for rec in dataSet:\n",
    "        if rec[2] is None:\n",
    "            continue\n",
    "\n",
    "        for i in range(0, len(rec)):\n",
    "            v = rec[i]\n",
    "            if i > 0: outFile.write(deli)\n",
    "            outFile.write('' if v is None else str(v))\n",
    "        outFile.write('\\n')\n",
    "\n",
    "    # end of crawlCompFinancials\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRAT at 2022-05-28 15:03:41.823546\n"
     ]
    }
   ],
   "source": [
    "print('STRAT at', dt.datetime.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. 기업 코드 / 업종 정보 가져 오기\n",
    "\n",
    "def step0_writeCodes():\n",
    "    deli = '\\t'\n",
    "    columnNames, records = getCompanyCodes()\n",
    "    \n",
    "    print('writing', codePathFile)\n",
    "    outFile = open(codePathFile, 'w', encoding='utf-8')\n",
    "    outFile.write(deli.join(columnNames))\n",
    "    outFile.write('\\n')\n",
    "    \n",
    "    for rec in records:\n",
    "        outFile.write(deli.join(rec))\n",
    "        outFile.write('\\n')\n",
    "    \n",
    "    outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0-1. 업종정보 페치\n",
    "jobName = 'getting company codes'\n",
    "begin(jobName)\n",
    "step0_writeCodes()\n",
    "end(jobName)\n",
    "\n",
    "\n",
    "# 0-2. 회사 정보 DB 로딩\n",
    "jobName = 'upload company info to db'\n",
    "begin(jobName)\n",
    "\n",
    "scriptPathName = crawlegoScriptPath + 'COMPANY.xml'\n",
    "parameter = { 'DATAPATH': codePathFile, 'DO_SERVER': '13.124.29.70' }\n",
    "\n",
    "retCode = runDashScript(scriptPathName, parameter)\n",
    "\n",
    "end(jobName)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>> setup company codes started\n",
      "codes 2579 2579 500\n",
      "<<<<<<< setup company codes done 23 ms\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터를 가져올 회사 정보 가져 오기\n",
    "jobName = 'setup company codes'\n",
    "begin(jobName)\n",
    "\n",
    "(codes, types, referCodes) = getCompanyCodeFromFile(codePathFile)\n",
    "print('codes', len(codes), len(types), len(referCodes)) # 첫 번째, 두 번째 값 같아야 함.\n",
    "\n",
    "end(jobName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 업종별 재무 데이터 항목 가져와 파일에 저장하기 (매번 수행할 필요 없음)\n",
    "# 최종 필요한 파일은 Step 3에서 생성되는 파일로 여기서 crawling하는 데이터는 임시 폴더에 넣음\n",
    "\n",
    "def step2_crawAcNames():\n",
    "    jobName = 'crawling data name'\n",
    "    begin(jobName)\n",
    "\n",
    "    print('reference codes count: ', len(referCodes))\n",
    "    fetchFunc = { 'annualBS': fetchFinacialData, 'annualCF': fetchCashFlowData, 'annualPL': fetchProfitLossData }\n",
    "\n",
    "    for dataType in fetchFunc.keys():\n",
    "        doFetchDataNames(referCodes, temporaryPath, dataType, fetchFunc[dataType])\n",
    "\n",
    "    end(jobName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 2에서 가져온 재무 항목 정리 (매번 수행할 필요 없음)\n",
    "# Crawlego 스크립트 실행 (AC-CODE-SAVE.xml)\n",
    "# ./resource 폴더 내 accCodes-XX.txt 파일 생성 (XX: BS, CF, PL)\n",
    "\n",
    "def step3_cleanupAcNames():\n",
    "    jobName = '데이터 항목명 정리 작업'\n",
    "    begin(jobName)\n",
    "\n",
    "    # IN_PATH(temporaryPath), OUT_PATH (resourceDir), TYPE(BS, CF, PL)\n",
    "    scriptPathName = crawlegoScriptPath + 'AC-CODE-SAVE.xml'\n",
    "\n",
    "    for typeStr in ['BS', 'CF', 'PL']:\n",
    "        parameter = { 'IN_PATH': temporaryPath, 'OUT_PATH': resourceDir, 'TYPE': typeStr }\n",
    "        retCode = runDashScript(scriptPathName, parameter)\n",
    "        print('Type', typeStr, 'processed.', 'return code', retCode, flush=True)\n",
    "\n",
    "    end(jobName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수집할 데이터 항목을 다시 정리하려면 아래 두 함수를 순차적으로 실행\n",
    "if doingAllJob:\n",
    "    step2_crawAcNames()\n",
    "    step3_cleanupAcNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>> 수집 대상 항목 메모리 로딩 started\n",
      "Type BS processed.\n",
      "Type CF processed.\n",
      "Type PL processed.\n",
      "Business Category Count: 6\n",
      "[ 0 ] 금융(기타금융);금융(창업투자);기타금융업(카드);\n",
      "[ 1 ] 보험업(생명보험);보험업(손해보험);\n",
      "[ 2 ] 기타금융업(손해보험);기타금융업(은행);은행(은행);\n",
      "[ 3 ] 금융(증권);금융서비스(증권);증권(증권);\n",
      "[ 4 ] 금융서비스(미분류);금융서비스(창업투자);기타금융업(부동산);기타금융업(운송인프라);기타금융업(창업투자);미분류(미분류);\n",
      "[ 99 ] BASIC\n",
      "<<<<<<< 수집 대상 항목 메모리 로딩 done 22 ms\n"
     ]
    }
   ],
   "source": [
    "# 4. 3에서 분석된 재무 항목을 업종별 컬럼목록 객체로 변환하여 반환\n",
    "\n",
    "jobName = '수집 대상 항목 메모리 로딩'\n",
    "begin(jobName)\n",
    "\n",
    "# 데이터 종류별(BS, CF, PL) --> 업종별 --> 데이터 항목 { accMap: 컬럼코드 --> 인덱스, accNames: 컬럼명 목록 }\n",
    "columnsMap = {}\n",
    "dupChecker = {}\n",
    "businessIndex = []\n",
    "businessKey = []\n",
    "\n",
    "for typeStr in ['BS', 'CF', 'PL']:\n",
    "    columnNameFile = resourceDir + 'accCodes-' + typeStr + '.txt' # step3_cleanupAcNames()에서 생성\n",
    "\n",
    "    file = open(columnNameFile, 'r', encoding='utf-8')\n",
    "    line = file.readline() # Title\n",
    "\n",
    "    cMap = {}\n",
    "\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        line = line.strip()\n",
    "        if len(line) <= 0:\n",
    "            continue\n",
    "\n",
    "        # 업종구분, ACCODE, NAME, P_ACCODE\n",
    "        items = line.split('\\t')\n",
    "        \n",
    "        if not items[0] in dupChecker:# 업종구분 (업종명)\n",
    "            dupChecker[items[0]] = True\n",
    "            if items[0] != 'BASIC': \n",
    "                businessIndex.append(items[0])\n",
    "                businessKey.append(items[0])\n",
    "\n",
    "        if not items[0] in cMap:\n",
    "            cMap[items[0]] = { 'accMap':{}, 'accNames':[] }\n",
    "\n",
    "        theItem = cMap[items[0]]\n",
    "\n",
    "        theItem['accMap'][items[1]] = len(theItem['accNames'])\n",
    "        theItem['accNames'].append(items[2])\n",
    "\n",
    "    file.close()\n",
    "    columnsMap[typeStr] = cMap\n",
    "\n",
    "    print('Type', typeStr, 'processed.', flush=True)\n",
    "\n",
    "# print(columnsMap)\n",
    "dupCheker = {}\n",
    "\n",
    "\n",
    "def printBusinessIndex():\n",
    "    print('Business Category Count:', len(businessIndex) + 1)\n",
    "    \n",
    "    for i in range(0, len(businessIndex)):\n",
    "        print('[', i, ']', businessIndex[i])\n",
    "    print('[', 99, ']', 'BASIC')\n",
    "\n",
    "'''\n",
    "printBusinessIndex() 아래와 같이 화면에 표시\n",
    "재무제표 항목이 동일 업종끼리 묶었을 때 이와 같이 나타남.\n",
    "예를 들어, \"금융(기타금융);금융(창업투자);기타금융업(카드);\" 업종들의 경우 같은 재무제표 항목을 갖는 것임.\n",
    "99는 일반기업을 의미\n",
    "\n",
    "[ 0 ] 금융(기타금융);금융(창업투자);기타금융업(카드);\n",
    "[ 1 ] 보험업(생명보험);보험업(손해보험);\n",
    "[ 2 ] 기타금융업(손해보험);기타금융업(은행);은행(은행);\n",
    "[ 3 ] 금융(증권);금융서비스(증권);증권(증권);\n",
    "[ 4 ] 금융서비스(미분류);금융서비스(창업투자);기타금융업(부동산);기타금융업(운송인프라);기타금융업(창업투자);미분류(미분류);\n",
    "[ 99 ] BASIC\n",
    "''' \n",
    "printBusinessIndex()\n",
    "\n",
    "end(jobName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 회사 업종별로 분리하여 저장\n",
    "basicCode = 99\n",
    "\n",
    "# 결과 저장 폴더 확인 및 생성\n",
    "mkdir(outputDirPath)\n",
    "\n",
    "# 업종명에 해당하는 그룹 인덱스 반환. basicCode는 기본 종류.\n",
    "# 그룹 인덱스는 printBusinessIndex()로 표시된 [ # ]을 의미함\n",
    "def getBusinessIndex(typeStr):\n",
    "    for i in range(0, len(businessIndex)):\n",
    "        if -1 != businessIndex[i].find(typeStr + ';'):\n",
    "            return i\n",
    "    return basicCode\n",
    "\n",
    "# codes, types에서 업종별 코드 목록을 저장함.\n",
    "# { basicCode--> [코드], 0 --> [코드], .. }\n",
    "categoricCodes = {}\n",
    "\n",
    "columnsMap['BS'].keys()\n",
    "\n",
    "for i in range(0, len(codes)):\n",
    "    bIdx = getBusinessIndex(types[i])\n",
    "    if not bIdx in categoricCodes:\n",
    "        categoricCodes[bIdx] = []\n",
    "    \n",
    "    categoricCodes[bIdx].append(codes[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#6. 회사별 재무제표 가져오기 업종에 따라 다른 파일에 저장됨.\n",
    "\n",
    "begin('crawing financial data')\n",
    "\n",
    "# 데이터 페치 함수 정의\n",
    "fetchFuncMap = { 'annualBS': fetchFinacialData, 'annualCF': fetchCashFlowData, 'annualPL': fetchProfitLossData,\n",
    "    'quarterBS': fetchQuaterFinacialData, 'quarterCF': fetchQuaterCashFlowData, 'quarterPL': fetchQuaterProfitLossData }\n",
    "\n",
    "for typeStr in ['BS', 'CF', 'PL']:\n",
    "    tmpMap = columnsMap[typeStr]\n",
    "\n",
    "    for keyIndex in categoricCodes.keys():\n",
    "        codeList = categoricCodes[keyIndex]\n",
    "        accMap = tmpMap['BASIC' if keyIndex == basicCode else businessKey[keyIndex]]\n",
    "    \n",
    "        for periodStr in ['annual', 'quarter']:\n",
    "            dataType = periodStr + typeStr\n",
    "            jobName = 'B' + str(keyIndex) + '.' + dataType \n",
    "\n",
    "            begin(jobName)\n",
    "            \n",
    "            deli = '\\t'\n",
    "            outFile = open(outputDirPath + jobName + '.txt', 'w', encoding='utf-8') # outputDirPath: output path + 날짜\n",
    "            outFile.write('P_CODE' + deli + 'TERM')\n",
    "            \n",
    "            for nn in accMap['accNames']:\n",
    "                outFile.write(deli)\n",
    "                outFile.write(nn)\n",
    "\n",
    "            outFile.write('\\n')\n",
    "            crawlCompFinancials(codeList, outFile, accMap['accMap'], len(accMap['accNames']), fetchFuncMap[dataType])\n",
    "\n",
    "            outFile.close()\n",
    "            end(jobName)\n",
    "\n",
    "printBusinessIndex()\n",
    "\n",
    "for key in categoricCodes.keys():\n",
    "    print(key, 'count:', len(categoricCodes[key]))\n",
    "\n",
    "end('crawing financial data')\n",
    "# end of category loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. HTML 소스에서 재무정보 가져오기\n",
    "\n",
    "begin('crawing basic status from HTML')\n",
    "\n",
    "deli = '\\t'\n",
    "for basis in ['Q', 'Y']:\n",
    "    begin('get data from HTML [' + basis + ']')\n",
    "    \n",
    "    for keyIndex in categoricCodes.keys():\n",
    "        begin('business type ' + str(keyIndex))\n",
    "        \n",
    "        # 대상 기업 코드\n",
    "        codeList = categoricCodes[keyIndex]\n",
    "\n",
    "        # 컬럼명칭\n",
    "        (valueTitle, yearTitle) = getDataTitles(basis, codeList[0])\n",
    "        columnNames = \"P_CODE\" + deli + \"TERM\" + deli + deli.join(valueTitle)\n",
    "        \n",
    "        # 저장할 파일 열기\n",
    "        savedPathName = outputDirPath + 'B' + str(keyIndex) + '.' + ('annual' if basis == 'Y' else 'quarter') + 'HTML' + '.txt'\n",
    "        outFile = open(savedPathName, 'w', encoding='utf-8')\n",
    "        outFile.write(columnNames)\n",
    "        outFile.write(\"\\n\")\n",
    "    \n",
    "        for code in codeList:\n",
    "            print('fetching', code, flush=True)\n",
    "            da = getDataArray(code, basis)\n",
    "            if da is None:\n",
    "                print('no data', flush=True)\n",
    "                continue\n",
    "\n",
    "            (data, yearTitle) = da\n",
    "\n",
    "            for i in range(0, len(yearTitle)):\n",
    "                if len(data[0][i]) == 0 or data[0][i] is None:\n",
    "                    continue\n",
    "                outFile.write(code)\n",
    "                outFile.write(\"\\t\")\n",
    "                outFile.write(yearTitle[i])\n",
    "\n",
    "                for j in range(0, len(data)):\n",
    "                    outFile.write(\"\\t\")\n",
    "                    outFile.write(str(data[j][i]))\n",
    "\n",
    "                outFile.write(\"\\n\")\n",
    "\n",
    "        outFile.close()\n",
    "        end('business type ' + str(keyIndex))\n",
    "        \n",
    "    end('get data from HTML [' + basis + ']')\n",
    "    \n",
    "printBusinessIndex()\n",
    "\n",
    "for key in categoricCodes.keys():\n",
    "    print(key, 'count:', len(categoricCodes[key]))\n",
    "    \n",
    "end('crawing basic status')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. DB에 넣기 (dataOn 사용)\n",
    "scriptPathName = crawlegoScriptPath + 'BS-CF-PL.xml'\n",
    "\n",
    "# 업종 99(일반 기업)만 넣음\n",
    "for rType in ['annual', 'quarter']:\n",
    "    jobName = 'upload ' + rType + ' to db'\n",
    "    begin(jobName)\n",
    "    parameter = { 'IN_PATH': outputDirPath, 'PERIOD': rType, 'DO_SERVER': '13.124.29.70' }\n",
    "    retCode = runDashScript(scriptPathName, parameter)\n",
    "    end(jobName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('END at', dt.datetime.today())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
