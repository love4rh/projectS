{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on Windows\n",
      "enc_param UWtSVjg4a0tjL3psTkRScjMzdDFtQT09\n",
      "codeFile D:\\work\\jupyter\\krx\\resource\\companyInfo-20210530.txt\n",
      "outputFolder D:\\work\\jupyter\\krx\\output\\\n"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "from commonTool import *\n",
    "from config import *\n",
    "\n",
    "# Parameter 설정\n",
    "set_enc_param(encParamKey)\n",
    "\n",
    "print('enc_param', enc_param_value)\n",
    "print('codeFile', codePathFile)\n",
    "print('outputFolder', outputRawPath, flush=True)\n",
    "\n",
    "\n",
    "# https://kind.krx.co.kr/corpgeneral/corpList.do?method=loadInitPage --> 메뉴 중 상장법인 목록\n",
    "# 위에서 Excel로 내려 받은 파일임\n",
    "# (code 목록, 업종 목록, 업종별 대표 코드 목록)을 반환.\n",
    "def getCompanyCodeFromFile():\n",
    "    codes = []\n",
    "    types = []\n",
    "    referCodes = []\n",
    "    referChecker = {}\n",
    "\n",
    "    fileCodes = open(codePathFile, 'r', encoding='utf-8')\n",
    "    line = fileCodes.readline() # Title\n",
    "    \n",
    "    while True:\n",
    "        line = fileCodes.readline()\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        line = line.strip()\n",
    "        if len(line) <= 0:\n",
    "            continue\n",
    "\n",
    "        items = line.split('\\t')\n",
    "        \n",
    "        codes.append(items[1])\n",
    "        types.append(items[2])\n",
    "        \n",
    "        if not items[2] in referChecker:\n",
    "            referChecker[items[2]] = items[1]\n",
    "            referCodes.append(items[1])\n",
    "\n",
    "    fileCodes.close()\n",
    "    \n",
    "    return (codes, types, referCodes)\n",
    "\n",
    "\n",
    "\n",
    "# 데이터명 분석을 위한 데이터 페치\n",
    "def doFetchDataNames(referenceCodes, outPath, fetchType, funcGet):\n",
    "    print(fetchType, 'doing...', flush=True)\n",
    "    deli = '\\t'\n",
    "    # keyNames = ['ACCODE', 'ACC_NM', 'UNT_TYP', 'P_ACCODE', 'DATA1', 'DATA2', 'DATA3', 'DATA4', 'DATA5']\n",
    "    valueColumns = ['DATA1', 'DATA2', 'DATA3', 'DATA4', 'DATA5']\n",
    "\n",
    "    out = open(outPath + fetchType + '-accNames.txt', 'w', encoding='utf-8')\n",
    "    out.write('PCODE' + deli + 'ACCODE' + deli + 'NAME' + deli + 'P_ACCODE\\n')\n",
    "\n",
    "    for code in referenceCodes:\n",
    "        # print('fetching', code, flush=True)\n",
    "        resp = funcGet(code)\n",
    "\n",
    "        if resp.status_code == 200:\n",
    "            # print(resp.text, flush=True)\n",
    "            obj = json.loads(resp.text)\n",
    "            if obj is None: continue\n",
    "            \n",
    "            data = obj['DATA']\n",
    "            if data is None:\n",
    "                continue\n",
    "\n",
    "            accodeMap = {}\n",
    "            \n",
    "            for rec in data:\n",
    "                if not rec['ACCODE'] in accodeMap:\n",
    "                    accNm = rec['ACC_NM'].lstrip('.').lstrip('*')\n",
    "                    accodeMap[rec['ACCODE']] = { 'name': accNm, 'pCode': rec['P_ACCODE'] }\n",
    "                    \n",
    "            # 추출한 데이터 명칭 저장\n",
    "            \n",
    "            for key in accodeMap.keys():\n",
    "                elem = accodeMap[key]\n",
    "                accNm = elem['name']\n",
    "                \n",
    "                out.write(code)\n",
    "                out.write(deli)\n",
    "                out.write(key)\n",
    "                out.write(deli)\n",
    "                out.write(accNm if elem['pCode'] is None else accodeMap[elem['pCode']]['name'] + '/' + accNm)\n",
    "                out.write(deli)\n",
    "                out.write('' if elem['pCode'] is None else elem['pCode'])\n",
    "                out.write('\\n')\n",
    "            \n",
    "        else:\n",
    "            print('fetch error ', code, resp.status_code)\n",
    "\n",
    "    out.close()\n",
    "    print(fetchType, 'done...', flush=True)\n",
    "\n",
    "    \n",
    "# codeList: 데이터를 가져올 회사 코드 목록\n",
    "# outFile: 결과를 저장할 파일\n",
    "# accCheck: 크롤링할 데이터 항목 맵. 항목 코드 --> 컬럼 위치\n",
    "# accCount: 데이터 항목 개수\n",
    "# funcGet: 크롤링 함수\n",
    "def crawlCompFinancials(codeList, outFile, accCheck, accCount, funcGet):\n",
    "    deli = '\\t'\n",
    "    valueColumns = ['DATA1', 'DATA2', 'DATA3', 'DATA4', 'DATA5']\n",
    "    \n",
    "    dataSet = [] # 크롤링 데이터 저장\n",
    "    for code in codeList:\n",
    "        print('fetching', code, flush=True)\n",
    "        resp = funcGet(code)\n",
    "\n",
    "        if resp.status_code == 200:\n",
    "            # print(resp.text, flush=True)\n",
    "            obj = json.loads(resp.text)\n",
    "            if obj is None: continue\n",
    "            \n",
    "            # DATA1 ~ DATA5의 기준 년월\n",
    "            yearName = [T[0:T.find('<')] for T in obj['YYMM']][0:len(valueColumns)]\n",
    "\n",
    "            data = obj['DATA']\n",
    "            if data is None:\n",
    "                continue\n",
    "\n",
    "            items = [extendList([code, title], accCount + 2) for title in yearName] # DATA1, ..., DATA4\n",
    "            \n",
    "            for rec in data:\n",
    "                if not rec['ACCODE'] in accCheck:\n",
    "                    accCheck[rec['ACCODE']] = len(accNames)\n",
    "                    accNm = rec['ACC_NM'].lstrip('.').lstrip('*')\n",
    "                    accNames.append(accNm if rec['P_ACCODE'] is None else accNames[accCheck[rec['P_ACCODE']]] + '/' + accNm)\n",
    "                    accItems.append([rec['ACCODE'], accNames[-1], rec['P_ACCODE']])\n",
    "                    items = [extendList(T, len(accNames) + 2) for T in items]\n",
    "\n",
    "                # 저장할 위치\n",
    "                valCol = accCheck[rec['ACCODE']] + 2\n",
    "                \n",
    "                for c in range(0, len(items)):\n",
    "                    items[c][valCol] = rec[valueColumns[c]]\n",
    "\n",
    "            # 결과 저장용 배열에 추가\n",
    "            dataSet.extend(items)\n",
    "        else:\n",
    "            print('fetch error ', code, resp.status_code)\n",
    "\n",
    "    # 추출한 데이터 저장\n",
    "    for rec in dataSet:\n",
    "        if rec[2] is None:\n",
    "            continue\n",
    "\n",
    "        for i in range(0, len(rec)):\n",
    "            v = rec[i]\n",
    "            if i > 0: outFile.write(deli)\n",
    "            outFile.write('' if v is None else str(v))\n",
    "        outFile.write('\\n')\n",
    "\n",
    "    # end of crawlCompFinancials\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>> setup company codes started\n",
      "codes 2449 2449 160\n",
      "<<<<<<< setup company codes done 26 ms\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터를 가져올 회사 정보 가져 오기\n",
    "jobName = 'setup company codes'\n",
    "begin(jobName)\n",
    "\n",
    "(codes, types, referCodes) = getCompanyCodeFromFile()\n",
    "print('codes', len(codes), len(types), len(referCodes)) # 첫 번째, 두 번째 값 같아야 함.\n",
    "\n",
    "end(jobName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 업종별 재무 데이터 항목 가져와 파일에 저장하기 (매번 수행할 필요 없음)\n",
    "# 최종 필요한 파일은 Step 3에서 생성되는 파일로 여기서 crawling하는 데이터는 임시 폴더에 넣음\n",
    "\n",
    "jobName = 'crawling data name'\n",
    "begin(jobName)\n",
    "\n",
    "print('reference codes count: ', len(referCodes))\n",
    "fetchFunc = { 'annualBS': fetchFinacialData, 'annualCF': fetchCashFlowData, 'annualPL': fetchProfitLossData }\n",
    "\n",
    "for dataType in fetchFunc.keys():\n",
    "    doFetchDataNames(referCodes, temporaryPath, dataType, fetchFunc[dataType])\n",
    "\n",
    "end(jobName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>> 데이터 항목명 정리 작업 started\n",
      "Type BS processed. return code 0\n",
      "Type CF processed. return code 0\n",
      "Type PL processed. return code 0\n",
      "<<<<<<< 데이터 항목명 정리 작업 done 8349 ms\n"
     ]
    }
   ],
   "source": [
    "# 3. 2에서 가져온 재무 항목 정리 (매번 수행할 필요 없음)\n",
    "# Crawlego 스크립트 실행 (AC-CODE-SAVE.xml)\n",
    "# ./resource 폴더 내 accCodes-XX.txt 파일 생성 (XX: BS, CF, PL)\n",
    "\n",
    "jobName = '데이터 항목명 정리 작업'\n",
    "begin(jobName)\n",
    "\n",
    "# IN_PATH(temporaryPath), OUT_PATH (resourceDir), TYPE(BS, CF, PL)\n",
    "scriptPathName = crawlegoScriptPath + 'AC-CODE-SAVE.xml'\n",
    "\n",
    "for typeStr in ['BS', 'CF', 'PL']:\n",
    "    cmdStr = 'java -Dfile.encoding=utf8 -Duser.timezone=GMT -jar ' + crawlegoPath + ' ' + scriptPathName \\\n",
    "        + ' IN_PATH=' + temporaryPath + ' OUT_PATH=' + resourceDir + ' TYPE=' + typeStr\n",
    "    retCode = os.system(cmdStr)\n",
    "    print('Type', typeStr, 'processed.', 'return code', retCode, flush=True)\n",
    "\n",
    "end(jobName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>> 수집 대상 항목 메모리 로딩 started\n",
      "Type BS processed.\n",
      "Type CF processed.\n",
      "Type PL processed.\n",
      "<<<<<<< 수집 대상 항목 메모리 로딩 done 27 ms\n"
     ]
    }
   ],
   "source": [
    "# 4. 3에서 분석된 재무 항목을 업종별 컬럼목록 객체로 변환하여 반환\n",
    "\n",
    "jobName = '수집 대상 항목 메모리 로딩'\n",
    "begin(jobName)\n",
    "\n",
    "# 데이터 종류별 --> 업종별 --> 데이터 항목 { accMap: 컬럼코드 --> 인덱스, accNames: 컬럼명 목록 }\n",
    "columnsMap = {}\n",
    "\n",
    "for typeStr in ['BS', 'CF', 'PL']:\n",
    "    columnNameFile = resourceDir + 'accCodes-' + typeStr + '.txt'\n",
    "\n",
    "    file = open(columnNameFile, 'r', encoding='utf-8')\n",
    "    line = file.readline() # Title\n",
    "\n",
    "    cMap = {}\n",
    "\n",
    "\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line:\n",
    "            break\n",
    "\n",
    "        line = line.strip()\n",
    "        if len(line) <= 0:\n",
    "            continue\n",
    "\n",
    "        # 업종구분, ACCODE, NAME, P_ACCODE\n",
    "        items = line.split('\\t')\n",
    "\n",
    "        if not items[0] in cMap:\n",
    "            cMap[items[0]] = { 'accMap':{}, 'accNames':[] }\n",
    "\n",
    "        theItem = cMap[items[0]]\n",
    "\n",
    "        theItem['accMap'][items[1]] = len(theItem['accNames'])\n",
    "        theItem['accNames'].append(items[2])\n",
    "\n",
    "    file.close()\n",
    "    columnsMap[typeStr] = cMap\n",
    "\n",
    "    print('Type', typeStr, 'processed.', flush=True)\n",
    "\n",
    "# print(columnsMap)\n",
    "\n",
    "end(jobName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>> crawing financial data started\n",
      ">>>>>>> annualBS started\n",
      "fetching 383310\n",
      "fetching 352480\n",
      "<<<<<<< annualBS done 427 ms\n",
      ">>>>>>> quarterBS started\n",
      "fetching 383310\n",
      "fetching 352480\n",
      "<<<<<<< quarterBS done 424 ms\n",
      ">>>>>>> annualBS started\n",
      "fetching 383800\n",
      "<<<<<<< annualBS done 196 ms\n",
      ">>>>>>> quarterBS started\n",
      "fetching 383800\n",
      "<<<<<<< quarterBS done 217 ms\n",
      ">>>>>>> annualBS started\n",
      "fetching 276730\n",
      "<<<<<<< annualBS done 230 ms\n",
      ">>>>>>> quarterBS started\n",
      "fetching 276730\n",
      "<<<<<<< quarterBS done 233 ms\n",
      ">>>>>>> annualBS started\n",
      "fetching 363250\n",
      "<<<<<<< annualBS done 246 ms\n",
      ">>>>>>> quarterBS started\n",
      "fetching 363250\n",
      "<<<<<<< quarterBS done 212 ms\n",
      ">>>>>>> annualBS started\n",
      "fetching 383220\n",
      "<<<<<<< annualBS done 201 ms\n",
      ">>>>>>> quarterBS started\n",
      "fetching 383220\n",
      "<<<<<<< quarterBS done 200 ms\n",
      ">>>>>>> annualBS started\n",
      "fetching 377630\n",
      "fetching 380440\n",
      "<<<<<<< annualBS done 342 ms\n",
      ">>>>>>> quarterBS started\n",
      "fetching 377630\n",
      "fetching 380440\n",
      "<<<<<<< quarterBS done 318 ms\n",
      ">>>>>>> annualBS started\n",
      "fetching 361670\n",
      "fetching 252990\n",
      "<<<<<<< annualBS done 452 ms\n",
      ">>>>>>> quarterBS started\n",
      "fetching 361670\n",
      "fetching 252990\n",
      "<<<<<<< quarterBS done 431 ms\n",
      ">>>>>>> annualCF started\n",
      "fetching 383310\n",
      "fetching 352480\n",
      "<<<<<<< annualCF done 489 ms\n",
      ">>>>>>> quarterCF started\n",
      "fetching 383310\n",
      "fetching 352480\n",
      "<<<<<<< quarterCF done 464 ms\n",
      ">>>>>>> annualCF started\n",
      "fetching 383800\n",
      "<<<<<<< annualCF done 220 ms\n",
      ">>>>>>> quarterCF started\n",
      "fetching 383800\n",
      "<<<<<<< quarterCF done 230 ms\n",
      ">>>>>>> annualCF started\n",
      "fetching 276730\n",
      "<<<<<<< annualCF done 251 ms\n",
      ">>>>>>> quarterCF started\n",
      "fetching 276730\n",
      "<<<<<<< quarterCF done 248 ms\n",
      ">>>>>>> annualCF started\n",
      "fetching 363250\n",
      "<<<<<<< annualCF done 270 ms\n",
      ">>>>>>> quarterCF started\n",
      "fetching 363250\n",
      "<<<<<<< quarterCF done 239 ms\n",
      ">>>>>>> annualCF started\n",
      "fetching 383220\n",
      "<<<<<<< annualCF done 221 ms\n",
      ">>>>>>> quarterCF started\n",
      "fetching 383220\n",
      "<<<<<<< quarterCF done 219 ms\n",
      ">>>>>>> annualCF started\n",
      "fetching 377630\n",
      "fetching 380440\n",
      "<<<<<<< annualCF done 454 ms\n",
      ">>>>>>> quarterCF started\n",
      "fetching 377630\n",
      "fetching 380440\n",
      "<<<<<<< quarterCF done 443 ms\n",
      ">>>>>>> annualCF started\n",
      "fetching 361670\n",
      "fetching 252990\n",
      "<<<<<<< annualCF done 525 ms\n",
      ">>>>>>> quarterCF started\n",
      "fetching 361670\n",
      "fetching 252990\n",
      "<<<<<<< quarterCF done 511 ms\n",
      ">>>>>>> annualPL started\n",
      "fetching 383310\n",
      "fetching 352480\n",
      "<<<<<<< annualPL done 419 ms\n",
      ">>>>>>> quarterPL started\n",
      "fetching 383310\n",
      "fetching 352480\n",
      "<<<<<<< quarterPL done 471 ms\n",
      ">>>>>>> annualPL started\n",
      "fetching 383800\n",
      "<<<<<<< annualPL done 193 ms\n",
      ">>>>>>> quarterPL started\n",
      "fetching 383800\n",
      "<<<<<<< quarterPL done 188 ms\n",
      ">>>>>>> annualPL started\n",
      "fetching 276730\n",
      "<<<<<<< annualPL done 215 ms\n",
      ">>>>>>> quarterPL started\n",
      "fetching 276730\n",
      "<<<<<<< quarterPL done 214 ms\n",
      ">>>>>>> annualPL started\n",
      "fetching 363250\n",
      "<<<<<<< annualPL done 227 ms\n",
      ">>>>>>> quarterPL started\n",
      "fetching 363250\n",
      "<<<<<<< quarterPL done 224 ms\n",
      ">>>>>>> annualPL started\n",
      "fetching 383220\n",
      "<<<<<<< annualPL done 202 ms\n",
      ">>>>>>> quarterPL started\n",
      "fetching 383220\n",
      "<<<<<<< quarterPL done 188 ms\n",
      ">>>>>>> annualPL started\n",
      "fetching 377630\n",
      "fetching 380440\n",
      "<<<<<<< annualPL done 292 ms\n",
      ">>>>>>> quarterPL started\n",
      "fetching 377630\n",
      "fetching 380440\n",
      "<<<<<<< quarterPL done 294 ms\n",
      ">>>>>>> annualPL started\n",
      "fetching 361670\n",
      "fetching 252990\n",
      "<<<<<<< annualPL done 442 ms\n",
      ">>>>>>> quarterPL started\n",
      "fetching 361670\n",
      "fetching 252990\n",
      "<<<<<<< quarterPL done 432 ms\n",
      "<<<<<<< crawing financial data done 12985 ms\n"
     ]
    }
   ],
   "source": [
    "# 5. 회사별 재무제표 가져오기 업종에 따라 다른 파일에 저장됨.\n",
    "\n",
    "# 데이터 페치 함수 정의\n",
    "fetchFuncMap = { 'annualBS': fetchFinacialData, 'annualCF': fetchCashFlowData, 'annualPL': fetchProfitLossData,\n",
    "    'quarterBS': fetchQuaterFinacialData, 'quarterCF': fetchQuaterCashFlowData, 'quarterPL': fetchQuaterProfitLossData }\n",
    "\n",
    "# codes, types --> 업종별 코드 목록\n",
    "categoricCodes = {}\n",
    "# for i in range(0, len(codes)):\n",
    "for i in range(0, 10):\n",
    "    if not types[i] in categoricCodes:\n",
    "        categoricCodes[types[i]] = []\n",
    "    \n",
    "    categoricCodes[types[i]].append(codes[i])\n",
    "\n",
    "begin('crawing financial data')\n",
    "for typeStr in ['BS', 'CF', 'PL']:\n",
    "    tmpMap = columnsMap[typeStr]\n",
    "\n",
    "    for typeKey in categoricCodes.keys():\n",
    "        codeList = categoricCodes[typeKey]\n",
    "        mapKey = 'BASIC'\n",
    "        keyIndex = 9\n",
    "        idx = 0\n",
    "        for s in tmpMap.keys():\n",
    "            if -1 != s.find(typeKey + ';'):\n",
    "                mapKey = s\n",
    "                keyIndex = idx\n",
    "                break\n",
    "            idx += 1\n",
    "\n",
    "        accMap = tmpMap[mapKey]\n",
    "    \n",
    "        for periodStr in ['annual', 'quarter']:\n",
    "            dataType = periodStr + typeStr\n",
    "            \n",
    "            begin(dataType)\n",
    "            \n",
    "            deli = '\\t'\n",
    "            outFile = open(outputRawPath + dataType + '-' + str(keyIndex) + '.txt', 'w', encoding='utf-8')\n",
    "            outFile.write('P_CODE' + deli + 'TERM')\n",
    "            \n",
    "            for nn in accMap['accNames']:\n",
    "                outFile.write(deli)\n",
    "                outFile.write(nn)\n",
    "\n",
    "            outFile.write('\\n')\n",
    "            \n",
    "            crawlCompFinancials(codeList, outFile, accMap['accMap'], len(accMap['accNames']), fetchFuncMap[dataType])\n",
    "\n",
    "            outFile.close()\n",
    "            end(dataType)\n",
    "\n",
    "end('crawing financial data')\n",
    "# end of category loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
