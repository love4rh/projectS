{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "from commonTool import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java -Dfile.encoding=utf8 -Duser.timezone=GMT -jar D:\\work\\jupyter\\krx\\jar\\crawlego-1.0.0.jar D:\\work\\jupyter\\krx\\script\\ZTMP_DATE.xml YEAR=2021 OUT_PATH=D:\\work\\jupyter\\krx\\output\\workingDay\\ DO_SERVER=13.124.29.70\n",
      "2021 ret code 0\n"
     ]
    }
   ],
   "source": [
    "# SP-1. 워킹 데이만 뽑아 저장하는 스크립트 실행\n",
    "workingDayPath = outputRawPath + 'workingDay' + os.path.sep\n",
    "mkdir(workingDayPath)\n",
    "\n",
    "currentYear = today()[0:4]\n",
    "\n",
    "scriptPathName = crawlegoScriptPath + 'BASIS_DATE.xml'\n",
    "for year in range(2012, int(currentYear) + 1):\n",
    "    if year != int(currentYear) and os.path.exists(workingDayPath + 'VD-' + str(year) + '.txt'):\n",
    "        continue\n",
    "\n",
    "    parameter = {\n",
    "        'YEAR': str(year),\n",
    "        'OUT_PATH': workingDayPath,\n",
    "        'DO_SERVER': '13.124.29.70'\n",
    "    }\n",
    "\n",
    "    print(year, 'ret code', runDashScript(scriptPathName, parameter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java -Dfile.encoding=utf8 -Duser.timezone=GMT -jar D:\\work\\jupyter\\krx\\jar\\crawlego-1.0.0.jar D:\\work\\jupyter\\krx\\script\\ZTMP_DATE_MINMAX.xml IN_PATH=D:\\work\\jupyter\\krx\\output\\workingDay\\ OUT_PATH=D:\\work\\jupyter\\krx\\resource\\\n",
      "ret code 0\n"
     ]
    }
   ],
   "source": [
    "# SP-2. 워킹 데이 중 달별로 기준일 추출하는 스크립트 실행\n",
    "# 매달 첫 째날, 둘 째날, 마지막 날, 마지막 전날 총 4일을 저장함\n",
    "# resourceDir에 BASIS_DAYs.txt와 주가 쿼리를 위한 날짜 조건을 담고 있는 BASIS-CONDITION.txt 파일 생성\n",
    "\n",
    "scriptPathName = crawlegoScriptPath + 'BASIS_DATE_MINMAX.xml'\n",
    "parameter = {\n",
    "    'IN_PATH': workingDayPath,\n",
    "    'OUT_PATH': resourceDir\n",
    "}\n",
    "\n",
    "print('ret code', runDashScript(scriptPathName, parameter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java -Dfile.encoding=utf8 -Duser.timezone=GMT -jar D:\\work\\jupyter\\krx\\jar\\crawlego-1.0.0.jar D:\\work\\jupyter\\krx\\script\\ZTMP_STOCK_PRICE.xml YEAR=2021 OUT_PATH=D:\\work\\jupyter\\krx\\intermediate\\ COND='20210104','20210105','20210128','20210129','20210201','20210202','20210225','20210226','20210302','20210303','20210330','20210331','20210401','20210402','20210429','20210430','20210503','20210504','20210528','20210531','20210601','20210602','20210617','20210618' DO_SERVER=13.124.29.70\n",
      "2021 ret code 0\n"
     ]
    }
   ],
   "source": [
    "# SP-3. SP-2의 BASIS-CONDITION.txt 파일을 읽어 해당 날짜의 주가를 쿼리하여 임시폴더에 저장함.\n",
    "\n",
    "scriptPathName = crawlegoScriptPath + 'BASIS_STOCK_PRICE.xml'\n",
    "\n",
    "bf = open(resourceDir + 'BASIS-CONDITION.txt', 'r', encoding='utf-8')\n",
    "\n",
    "lineText = bf.readline() # 제목\n",
    "\n",
    "while True:\n",
    "    lineText = bf.readline()\n",
    "    if not lineText:\n",
    "        break\n",
    "        \n",
    "    lineText = lineText.strip()\n",
    "    if len(lineText) <= 0:\n",
    "        continue\n",
    "        \n",
    "    dayData = lineText.split('\\t')\n",
    "    \n",
    "    # 금년만 계산하려면 아래 라인 살리기. 이전 년도는 BASIS가 바뀌지 않는한 변함 없음\n",
    "    # if dayData[0] != currentYear: continue\n",
    "    \n",
    "    parameter = {\n",
    "        'YEAR': dayData[0],\n",
    "        'COND': dayData[1],\n",
    "        'OUT_PATH': temporaryPath,\n",
    "        'DO_SERVER': '13.124.29.70'\n",
    "    }\n",
    "\n",
    "    print(dayData[0], 'ret code', runDashScript(scriptPathName, parameter))\n",
    "\n",
    "bf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java -Dfile.encoding=utf8 -Duser.timezone=GMT -jar D:\\work\\jupyter\\krx\\jar\\crawlego-1.0.0.jar D:\\work\\jupyter\\krx\\script\\ZTMP_MERGE_PRICE.xml IN_PATH=D:\\work\\jupyter\\krx\\intermediate\\ DO_SERVER=13.124.29.70\n",
      "ret code 1\n"
     ]
    }
   ],
   "source": [
    "# SP-4. 기준이 되는 날짜의 주가를 하나로 합쳐 DB에 업로딩.\n",
    "\n",
    "scriptPathName = crawlegoScriptPath + 'BASIS_MERGE_PRICE.xml'\n",
    "\n",
    "parameter = {\n",
    "    'IN_PATH': temporaryPath,\n",
    "    'DO_SERVER': '13.124.29.70'\n",
    "}\n",
    "\n",
    "print('ret code', runDashScript(scriptPathName, parameter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
